{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2340, 30, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'left',\n",
    "    'right',\n",
    "    'stop'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_left_1655896673.npy'),\n",
    "    np.load('dataset/seq_right_1655896673.npy'),\n",
    "    np.load('dataset/seq_stop_1655896673.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2340, 30, 99)\n",
      "(2340,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2340, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2106, 30, 99) (2106, 3)\n",
      "(234, 30, 99) (234, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                41984     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,163\n",
      "Trainable params: 44,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 65.5244 - acc: 0.3837\n",
      "Epoch 1: val_acc improved from -inf to 0.52564, saving model to models\\model.h5\n",
      "66/66 [==============================] - 3s 27ms/step - loss: 65.5244 - acc: 0.3837 - val_loss: 14.6067 - val_acc: 0.5256 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 24.0809 - acc: 0.4756\n",
      "Epoch 2: val_acc did not improve from 0.52564\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 24.0374 - acc: 0.4767 - val_loss: 12.1701 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 4.9500 - acc: 0.6120\n",
      "Epoch 3: val_acc improved from 0.52564 to 0.63675, saving model to models\\model.h5\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 4.9555 - acc: 0.6121 - val_loss: 3.8790 - val_acc: 0.6368 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "63/66 [===========================>..] - ETA: 0s - loss: 3.0886 - acc: 0.6855\n",
      "Epoch 4: val_acc improved from 0.63675 to 0.65385, saving model to models\\model.h5\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 3.0669 - acc: 0.6852 - val_loss: 1.8906 - val_acc: 0.6538 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "63/66 [===========================>..] - ETA: 0s - loss: 9.9863 - acc: 0.6473\n",
      "Epoch 5: val_acc did not improve from 0.65385\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 10.3449 - acc: 0.6410 - val_loss: 14.5185 - val_acc: 0.5812 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 11.6966 - acc: 0.6149\n",
      "Epoch 6: val_acc improved from 0.65385 to 0.67094, saving model to models\\model.h5\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 11.6160 - acc: 0.6144 - val_loss: 5.3766 - val_acc: 0.6709 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 5.3325 - acc: 0.6035\n",
      "Epoch 7: val_acc did not improve from 0.67094\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 5.3325 - acc: 0.6035 - val_loss: 5.2996 - val_acc: 0.5855 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 3.4284 - acc: 0.6406\n",
      "Epoch 8: val_acc improved from 0.67094 to 0.69231, saving model to models\\model.h5\n",
      "66/66 [==============================] - 1s 20ms/step - loss: 3.4213 - acc: 0.6425 - val_loss: 3.6982 - val_acc: 0.6923 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.5462 - acc: 0.7426\n",
      "Epoch 9: val_acc improved from 0.69231 to 0.82479, saving model to models\\model.h5\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 1.5462 - acc: 0.7426 - val_loss: 1.2535 - val_acc: 0.8248 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.1347 - acc: 0.8291\n",
      "Epoch 10: val_acc did not improve from 0.82479\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 1.1347 - acc: 0.8291 - val_loss: 3.7717 - val_acc: 0.6282 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 8.4559 - acc: 0.5645\n",
      "Epoch 11: val_acc did not improve from 0.82479\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 8.3222 - acc: 0.5670 - val_loss: 2.0892 - val_acc: 0.6795 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 1.1801 - acc: 0.8115\n",
      "Epoch 12: val_acc improved from 0.82479 to 0.84188, saving model to models\\model.h5\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 1.1609 - acc: 0.8129 - val_loss: 0.8385 - val_acc: 0.8419 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.7843 - acc: 0.8557\n",
      "Epoch 13: val_acc improved from 0.84188 to 0.84615, saving model to models\\model.h5\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.7843 - acc: 0.8557 - val_loss: 1.4385 - val_acc: 0.8462 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 0.6451 - acc: 0.8808\n",
      "Epoch 14: val_acc improved from 0.84615 to 0.93590, saving model to models\\model.h5\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 0.6431 - acc: 0.8813 - val_loss: 0.3186 - val_acc: 0.9359 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.3994 - acc: 0.9183\n",
      "Epoch 15: val_acc did not improve from 0.93590\n",
      "66/66 [==============================] - 2s 24ms/step - loss: 0.3994 - acc: 0.9183 - val_loss: 0.7585 - val_acc: 0.9231 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 0.4164 - acc: 0.9144\n",
      "Epoch 16: val_acc improved from 0.93590 to 0.97009, saving model to models\\model.h5\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.4426 - acc: 0.9126 - val_loss: 0.2430 - val_acc: 0.9701 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.5104 - acc: 0.9093\n",
      "Epoch 17: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 23ms/step - loss: 0.5104 - acc: 0.9093 - val_loss: 0.3634 - val_acc: 0.9274 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 0.3748 - acc: 0.9279\n",
      "Epoch 18: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.3721 - acc: 0.9278 - val_loss: 0.1524 - val_acc: 0.9359 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 1.0275 - acc: 0.8880\n",
      "Epoch 19: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 25ms/step - loss: 1.0569 - acc: 0.8865 - val_loss: 1.3014 - val_acc: 0.8504 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.6416 - acc: 0.9046\n",
      "Epoch 20: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 27ms/step - loss: 0.6416 - acc: 0.9046 - val_loss: 0.4810 - val_acc: 0.9444 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 2.8848 - acc: 0.8341\n",
      "Epoch 21: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 3.0077 - acc: 0.8305 - val_loss: 34.2187 - val_acc: 0.5855 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 73.6173 - acc: 0.4507\n",
      "Epoch 22: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 27ms/step - loss: 71.8884 - acc: 0.4525 - val_loss: 6.9456 - val_acc: 0.5897 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 59.6678 - acc: 0.3966\n",
      "Epoch 23: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 27ms/step - loss: 59.6420 - acc: 0.3974 - val_loss: 77.8180 - val_acc: 0.3077 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 59.0625 - acc: 0.3428\n",
      "Epoch 24: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 58.5416 - acc: 0.3419 - val_loss: 14.1019 - val_acc: 0.5556 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 8.0625 - acc: 0.6956\n",
      "Epoch 25: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 33ms/step - loss: 8.0625 - acc: 0.6956 - val_loss: 2.5528 - val_acc: 0.6880 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 3.2716 - acc: 0.8408\n",
      "Epoch 26: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 3.3239 - acc: 0.8414 - val_loss: 2.0066 - val_acc: 0.8974 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 2.2291 - acc: 0.8918\n",
      "Epoch 27: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 24ms/step - loss: 2.2483 - acc: 0.8908 - val_loss: 2.9676 - val_acc: 0.8462 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 5.9491 - acc: 0.6743\n",
      "Epoch 28: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 25ms/step - loss: 6.0473 - acc: 0.6738 - val_loss: 9.3541 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 7.5182 - acc: 0.5750\n",
      "Epoch 29: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 1s 23ms/step - loss: 7.4610 - acc: 0.5760 - val_loss: 3.1772 - val_acc: 0.6154 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 3.3728 - acc: 0.6361\n",
      "Epoch 30: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 23ms/step - loss: 3.3624 - acc: 0.6368 - val_loss: 2.0613 - val_acc: 0.6496 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 2.5959 - acc: 0.6899\n",
      "Epoch 31: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 26ms/step - loss: 2.5959 - acc: 0.6899 - val_loss: 4.7211 - val_acc: 0.6880 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 6.0628 - acc: 0.6514\n",
      "Epoch 32: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 3s 41ms/step - loss: 6.0272 - acc: 0.6505 - val_loss: 1.9224 - val_acc: 0.8675 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 2.6173 - acc: 0.7928\n",
      "Epoch 33: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 2.6962 - acc: 0.7920 - val_loss: 2.2142 - val_acc: 0.9017 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.7968 - acc: 0.8538\n",
      "Epoch 34: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 3s 47ms/step - loss: 1.7968 - acc: 0.8538 - val_loss: 1.8133 - val_acc: 0.6453 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.8019 - acc: 0.8500\n",
      "Epoch 35: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 3s 51ms/step - loss: 1.8019 - acc: 0.8500 - val_loss: 1.1676 - val_acc: 0.7735 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 3.1356 - acc: 0.7707\n",
      "Epoch 36: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 3s 44ms/step - loss: 3.1265 - acc: 0.7721 - val_loss: 3.7182 - val_acc: 0.7308 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 66.3308 - acc: 0.5668\n",
      "Epoch 37: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 65.9148 - acc: 0.5665 - val_loss: 93.5036 - val_acc: 0.5385 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 57.1297 - acc: 0.5708\n",
      "Epoch 38: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 28ms/step - loss: 57.1297 - acc: 0.5708 - val_loss: 19.4987 - val_acc: 0.7179 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 20.0907 - acc: 0.6681\n",
      "Epoch 39: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 20.0907 - acc: 0.6681 - val_loss: 70.1604 - val_acc: 0.5812 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 16.3506 - acc: 0.7293\n",
      "Epoch 40: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 28ms/step - loss: 16.3506 - acc: 0.7293 - val_loss: 81.9021 - val_acc: 0.7308 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 106.5308 - acc: 0.5107\n",
      "Epoch 41: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 27ms/step - loss: 103.9915 - acc: 0.5119 - val_loss: 18.4352 - val_acc: 0.5171 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 10.8661 - acc: 0.6343\n",
      "Epoch 42: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 10.7675 - acc: 0.6372 - val_loss: 6.1796 - val_acc: 0.6752 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 8.8081 - acc: 0.6899\n",
      "Epoch 43: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 27ms/step - loss: 9.0174 - acc: 0.6876 - val_loss: 34.7415 - val_acc: 0.4274 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 18.2361 - acc: 0.6192\n",
      "Epoch 44: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 25ms/step - loss: 18.2361 - acc: 0.6192 - val_loss: 5.3759 - val_acc: 0.8034 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 6.0990 - acc: 0.7755\n",
      "Epoch 45: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 29ms/step - loss: 6.0663 - acc: 0.7745 - val_loss: 6.5449 - val_acc: 0.6752 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 3.8833 - acc: 0.9005\n",
      "Epoch 46: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 27ms/step - loss: 3.8540 - acc: 0.9012 - val_loss: 4.0080 - val_acc: 0.9658 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 3.9743 - acc: 0.8721\n",
      "Epoch 47: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 27ms/step - loss: 3.9295 - acc: 0.8732 - val_loss: 6.5017 - val_acc: 0.9060 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 4.6091 - acc: 0.8666\n",
      "Epoch 48: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 28ms/step - loss: 4.6091 - acc: 0.8666 - val_loss: 4.6471 - val_acc: 0.9530 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 3.3584 - acc: 0.9438\n",
      "Epoch 49: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 29ms/step - loss: 3.3170 - acc: 0.9444 - val_loss: 4.7002 - val_acc: 0.8932 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "64/66 [============================>.] - ETA: 0s - loss: 7.2204 - acc: 0.7783\n",
      "Epoch 50: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 29ms/step - loss: 7.0436 - acc: 0.7825 - val_loss: 8.2080 - val_acc: 0.7821 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "65/66 [============================>.] - ETA: 0s - loss: 3.6041 - acc: 0.9312\n",
      "Epoch 51: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 25ms/step - loss: 3.7230 - acc: 0.9316 - val_loss: 3.8294 - val_acc: 0.9487 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "66/66 [==============================] - ETA: 0s - loss: 3.6179 - acc: 0.9221\n",
      "Epoch 52: val_acc did not improve from 0.97009\n",
      "66/66 [==============================] - 2s 26ms/step - loss: 3.6179 - acc: 0.9221 - val_loss: 5.2585 - val_acc: 0.9359 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "42/66 [==================>...........] - ETA: 0s - loss: 4.4306 - acc: 0.8750"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}